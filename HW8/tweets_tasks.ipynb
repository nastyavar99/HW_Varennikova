{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from emoji import emoji_lis\n",
    "\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'(Robert Smith)</th>\n",
       "      <td>A lecture on the spirit of the computer, recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(((E. Glen Weyl)))</th>\n",
       "      <td>Couldn't be more excited to put out probably m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(((Matthew Lewis)))</th>\n",
       "      <td>\"This could be huge.\"\\n\\nFolks, this *is* huge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(â—”_â—”) Â¯\\_(ãƒ„)_/Â¯</th>\n",
       "      <td>@EdLatimore The problem is twofold:\\n\\n1. Suga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1jack ğŸŒ±</th>\n",
       "      <td>Institutional money is going to move into this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğŸ”¥ #Author Abraham Lopez</th>\n",
       "      <td>@EdLatimore Misery doesnâ€™t just love company, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğŸ”­ğŸŒƒJana Grcevich ğŸ“¡ğŸš€</th>\n",
       "      <td>Hey #ancientegypt twitter: I would love to kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğŸ”±Master of EcstasyğŸ”±</th>\n",
       "      <td>I HAVE A NEW FAVORITE WORD:\\n\\nAPOTHEOSIS:\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğŸ¤™ğŸ½ Bobby D ğŸ¤ŸğŸ½</th>\n",
       "      <td>Ben Roethlisberger and Mike Tomlin watching th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğŸ¦‰ Wisdomination ğŸ¦‰</th>\n",
       "      <td>@naval American university is a peculiar mixtu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2170 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             tweet_content\n",
       "author_name                                                               \n",
       "'(Robert Smith)          A lecture on the spirit of the computer, recen...\n",
       "(((E. Glen Weyl)))       Couldn't be more excited to put out probably m...\n",
       "(((Matthew Lewis)))      \"This could be huge.\"\\n\\nFolks, this *is* huge...\n",
       "(â—”_â—”) Â¯\\_(ãƒ„)_/Â¯          @EdLatimore The problem is twofold:\\n\\n1. Suga...\n",
       "1jack ğŸŒ±                  Institutional money is going to move into this...\n",
       "...                                                                    ...\n",
       "ğŸ”¥ #Author Abraham Lopez  @EdLatimore Misery doesnâ€™t just love company, ...\n",
       "ğŸ”­ğŸŒƒJana Grcevich ğŸ“¡ğŸš€       Hey #ancientegypt twitter: I would love to kno...\n",
       "ğŸ”±Master of EcstasyğŸ”±      I HAVE A NEW FAVORITE WORD:\\n\\nAPOTHEOSIS:\\n\\n...\n",
       "ğŸ¤™ğŸ½ Bobby D ğŸ¤ŸğŸ½            Ben Roethlisberger and Mike Tomlin watching th...\n",
       "ğŸ¦‰ Wisdomination ğŸ¦‰        @naval American university is a peculiar mixtu...\n",
       "\n",
       "[2170 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 1\n",
    "df_sorted = df[df['author_name'].apply(lambda n: len(str(n).split()) >= 2)]\n",
    "df_sorted.groupby('author_name').agg({'tweet_content': lambda t: min(t, key=len)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('âœ…', 117),\n",
       " ('ğŸ‘‡', 101),\n",
       " ('ğŸ˜‚', 101),\n",
       " ('ğŸ”¥', 52),\n",
       " ('ğŸ»', 41),\n",
       " ('ğŸ™', 41),\n",
       " ('ğŸ½', 38),\n",
       " ('ğŸ‘', 34),\n",
       " ('â¤', 32),\n",
       " ('â™‚', 30),\n",
       " ('ğŸš¨', 30),\n",
       " ('ğŸ‡¸', 30),\n",
       " ('ğŸ‡º', 29),\n",
       " ('ğŸ¼', 26),\n",
       " ('ğŸ‘¨', 20),\n",
       " ('âš«', 19),\n",
       " ('ğŸ‘©', 18),\n",
       " ('ğŸ‘', 18),\n",
       " ('ğŸ’¯', 17),\n",
       " ('ğŸ¾', 17),\n",
       " ('ğŸ¤”', 17),\n",
       " ('ğŸ™Œ', 16),\n",
       " ('ğŸ†•', 16),\n",
       " ('â™€', 15),\n",
       " ('ğŸš€', 15),\n",
       " ('ğŸ’ª', 15),\n",
       " ('ğŸ‘‰', 14),\n",
       " ('â¤µ', 13),\n",
       " ('ğŸ™„', 13),\n",
       " ('ğŸ¤£', 13),\n",
       " ('ğŸ‘¦', 13),\n",
       " ('â¬‡', 12),\n",
       " ('ğŸ¿', 12),\n",
       " ('ğŸ‘§', 12),\n",
       " ('âšª', 12),\n",
       " ('ğŸ¤¦', 11),\n",
       " ('ğŸ’»', 11),\n",
       " ('ğŸ§ ', 10),\n",
       " ('ğŸ‡¦', 10),\n",
       " ('ğŸ˜', 10),\n",
       " ('ğŸ˜€', 9),\n",
       " ('ğŸ‘‹', 9),\n",
       " ('âœ', 9),\n",
       " ('ğŸ¤·', 9),\n",
       " ('ğŸ‘€', 9),\n",
       " ('ğŸ’€', 9),\n",
       " ('ğŸ’°', 8),\n",
       " ('â¡', 8),\n",
       " ('âœŒ', 8),\n",
       " ('ğŸ˜†', 8),\n",
       " ('ğŸ§', 8),\n",
       " ('âœ¨', 8),\n",
       " ('ğŸ‡ª', 8),\n",
       " ('âš¡', 8),\n",
       " ('ğŸ’­', 8),\n",
       " ('ğŸ‘‚', 8),\n",
       " ('ğŸ‹', 7),\n",
       " ('â–¶', 7),\n",
       " ('ğŸ‡¨', 7),\n",
       " ('ğŸ§˜', 7),\n",
       " ('ğŸ“ˆ', 7),\n",
       " ('ğŸŒŸ', 7),\n",
       " ('ğŸ˜', 7),\n",
       " ('â—', 7),\n",
       " ('ğŸ‰', 7),\n",
       " ('ğŸ¤¯', 7),\n",
       " ('ğŸ‘Š', 7),\n",
       " ('ğŸ‡®', 7),\n",
       " ('ğŸ‡µ', 7),\n",
       " ('ğŸ‡³', 7),\n",
       " ('ğŸ—£', 7),\n",
       " ('ğŸ‘Œ', 6),\n",
       " ('ğŸŒ±', 6),\n",
       " ('ğŸ˜Š', 6),\n",
       " ('ğŸ˜', 6),\n",
       " ('ğŸ“š', 6),\n",
       " ('ğŸ‡¯', 6),\n",
       " ('â­', 6),\n",
       " ('â', 5),\n",
       " ('â„¢', 5),\n",
       " ('ğŸ»', 5),\n",
       " ('ğŸ²', 5),\n",
       " ('ğŸ˜‰', 5),\n",
       " ('â™¥', 5),\n",
       " ('ğŸ¥', 5),\n",
       " ('ğŸ¤¤', 5),\n",
       " ('ğŸ”µ', 5),\n",
       " ('âœˆ', 5),\n",
       " ('ğŸ‘', 5),\n",
       " ('â™¦', 5),\n",
       " ('ğŸ“–', 4),\n",
       " ('ğŸ™', 4),\n",
       " ('ğŸ¤—', 4),\n",
       " ('ğŸ˜­', 4),\n",
       " ('ğŸ˜«', 4),\n",
       " ('ğŸ—', 4),\n",
       " ('ğŸ™ƒ', 4),\n",
       " ('ğŸ’œ', 4),\n",
       " ('ğŸ˜±', 4),\n",
       " ('ğŸ·', 4),\n",
       " ('ğŸ“', 4),\n",
       " ('ğŸ¥©', 4),\n",
       " ('ğŸ˜„', 4),\n",
       " ('ğŸ¥³', 4),\n",
       " ('ğŸ‡§', 4),\n",
       " ('ğŸ¤¨', 4),\n",
       " ('âŒ', 4),\n",
       " ('ğŸ˜¡', 4),\n",
       " ('â˜‘', 4),\n",
       " ('ğŸŒ', 3),\n",
       " ('ğŸ”½', 3),\n",
       " ('ğŸ˜”', 3),\n",
       " ('â˜º', 3),\n",
       " ('ğŸ’–', 3),\n",
       " ('ğŸ‡·', 3),\n",
       " ('ğŸ˜ˆ', 3),\n",
       " ('ğŸ¤¡', 3),\n",
       " ('ğŸ‡¹', 3),\n",
       " ('ğŸ‡©', 3),\n",
       " ('ğŸ‡­', 3),\n",
       " ('ğŸ‡¬', 3),\n",
       " ('ğŸ–', 3),\n",
       " ('ğŸ¦†', 3),\n",
       " ('ğŸ§¬', 3),\n",
       " ('ğŸ¶', 3),\n",
       " ('ğŸ˜´', 3),\n",
       " ('ğŸ’”', 3),\n",
       " ('ğŸ¤', 3),\n",
       " ('ğŸ“±', 3),\n",
       " ('ğŸ¤', 3),\n",
       " ('â˜€', 3),\n",
       " ('ğŸ¤¬', 3),\n",
       " ('ğŸ‡', 3),\n",
       " ('âœŠ', 3),\n",
       " ('ğŸ¨', 3),\n",
       " ('ğŸ’¡', 3),\n",
       " ('ğŸ™‚', 3),\n",
       " ('ğŸ’¸', 3),\n",
       " ('ğŸ¤«', 3),\n",
       " ('ğŸ¥ƒ', 3),\n",
       " ('ğŸ¤¢', 3),\n",
       " ('ğŸ', 3),\n",
       " ('ğŸ ', 2),\n",
       " ('ğŸ¦·', 2),\n",
       " ('ğŸ’£', 2),\n",
       " ('ğŸ§’', 2),\n",
       " ('â€¼', 2),\n",
       " ('ğŸ', 2),\n",
       " ('ğŸ˜“', 2),\n",
       " ('ğŸ”‘', 2),\n",
       " ('ğŸ¤±', 2),\n",
       " ('ğŸ†', 2),\n",
       " ('ğŸŒ·', 2),\n",
       " ('ğŸ˜ƒ', 2),\n",
       " ('ğŸ™', 2),\n",
       " ('ğŸ‡°', 2),\n",
       " ('ğŸ‡«', 2),\n",
       " ('ğŸ‡±', 2),\n",
       " ('ğŸ‡¿', 2),\n",
       " ('ğŸ¤²', 2),\n",
       " ('ğŸ¦„', 2),\n",
       " ('ğŸ‘¼', 2),\n",
       " ('ğŸ˜®', 2),\n",
       " ('ğŸ˜', 2),\n",
       " ('ğŸ¤©', 2),\n",
       " ('ğŸ', 2),\n",
       " ('ğŸ°', 2),\n",
       " ('â°', 2),\n",
       " ('ğŸ¥Š', 2),\n",
       " ('ğŸ˜–', 2),\n",
       " ('ğŸ¥¦', 2),\n",
       " ('ğŸ…', 2),\n",
       " ('ğŸš‡', 2),\n",
       " ('ğŸ—½', 2),\n",
       " ('ğŸ¤˜', 2),\n",
       " ('ğŸ§µ', 2),\n",
       " ('ğŸ“‰', 2),\n",
       " ('ğŸ’¥', 2),\n",
       " ('â˜¹', 2),\n",
       " ('ğŸŒŠ', 2),\n",
       " ('ğŸšµ', 2),\n",
       " ('ğŸŒ´', 2),\n",
       " ('ğŸ“¸', 2),\n",
       " ('ğŸ–', 2),\n",
       " ('ğŸ˜…', 2),\n",
       " ('ğŸ’¬', 2),\n",
       " ('ğŸ“°', 2),\n",
       " ('ğŸ˜•', 2),\n",
       " ('ğŸ‚', 2),\n",
       " ('â›”', 2),\n",
       " ('ğŸŒŒ', 1),\n",
       " ('ğŸ‘¤', 1),\n",
       " ('ğŸ“²', 1),\n",
       " ('â˜•', 1),\n",
       " ('ğŸµ', 1),\n",
       " ('ğŸ˜¸', 1),\n",
       " ('ğŸ”§', 1),\n",
       " ('ğŸ˜³', 1),\n",
       " ('ğŸ•µ', 1),\n",
       " ('ğŸ¼', 1),\n",
       " ('ğŸ¤–', 1),\n",
       " ('ğŸ–', 1),\n",
       " ('ğŸŒ¯', 1),\n",
       " ('ğŸ”', 1),\n",
       " ('ğŸ’', 1),\n",
       " ('ğŸ¤', 1),\n",
       " ('ğŸŒ¦', 1),\n",
       " ('ğŸœ', 1),\n",
       " ('ğŸŒ', 1),\n",
       " ('ğŸ¦‹', 1),\n",
       " ('ğŸ¥°', 1),\n",
       " ('ğŸ˜¢', 1),\n",
       " ('ğŸ˜¬', 1),\n",
       " ('ğŸ–•', 1),\n",
       " ('ğŸ', 1),\n",
       " ('ğŸŒ¶', 1),\n",
       " ('ğŸ’§', 1),\n",
       " ('ğŸ›', 1),\n",
       " ('ğŸ’™', 1),\n",
       " ('ğŸŒº', 1),\n",
       " ('ğŸŒ‰', 1),\n",
       " ('ğŸ¦', 1),\n",
       " ('ğŸ“Œ', 1),\n",
       " ('ğŸ«', 1),\n",
       " ('âœ', 1),\n",
       " ('ğŸ¾', 1),\n",
       " ('ğŸ”©', 1),\n",
       " ('ğŸ˜‘', 1),\n",
       " ('ğŸ–¤', 1),\n",
       " ('ğŸ‘¹', 1),\n",
       " ('ğŸ¯', 1),\n",
       " ('ğŸ¤­', 1),\n",
       " ('ğŸ‡²', 1),\n",
       " ('ğŸ‡½', 1),\n",
       " ('ğŸ¥º', 1),\n",
       " ('ğŸ¥ˆ', 1),\n",
       " ('ğŸƒ', 1),\n",
       " ('ğŸŒ§', 1),\n",
       " ('ğŸ™Š', 1),\n",
       " ('ğŸ¥¥', 1),\n",
       " ('ğŸŒ', 1),\n",
       " ('ğŸ¦', 1),\n",
       " ('ğŸ’¨', 1),\n",
       " ('ğŸ™…', 1),\n",
       " ('ğŸ¥µ', 1),\n",
       " ('ğŸ§”', 1),\n",
       " ('ğŸ‘', 1),\n",
       " ('âš°', 1),\n",
       " ('ğŸµ', 1),\n",
       " ('ğŸ•¸', 1),\n",
       " ('ğŸ”´', 1),\n",
       " ('ğŸš—', 1),\n",
       " ('ğŸ’´', 1),\n",
       " ('ğŸ‘¥', 1),\n",
       " ('ğŸ¤³', 1),\n",
       " ('ğŸš¶', 1),\n",
       " ('ğŸŒ³', 1),\n",
       " ('ğŸ§ª', 1),\n",
       " ('ğŸ“', 1),\n",
       " ('âš”', 1),\n",
       " ('ğŸ’µ', 1),\n",
       " ('ğŸ¤´', 1),\n",
       " ('ğŸ’', 1),\n",
       " ('ğŸ¹', 1),\n",
       " ('ğŸ—‘', 1),\n",
       " ('ğŸ¤¥', 1),\n",
       " ('ğŸ˜’', 1),\n",
       " ('ğŸ˜‡', 1),\n",
       " ('ğŸ‘¶', 1),\n",
       " ('ğŸ˜˜', 1),\n",
       " ('ğŸ’¤', 1),\n",
       " ('ğŸŒµ', 1),\n",
       " ('ğŸ‘³', 1),\n",
       " ('ğŸ‘“', 1),\n",
       " ('ğŸ·', 1),\n",
       " ('ğŸŸ', 1),\n",
       " ('ğŸ—', 1),\n",
       " ('ğŸ™‰', 1),\n",
       " ('ğŸ’¦', 1),\n",
       " ('ğŸ”¸', 1),\n",
       " ('ğŸ”¹', 1),\n",
       " ('ğŸ˜œ', 1),\n",
       " ('ğŸº', 1),\n",
       " ('ğŸ¦', 1),\n",
       " ('â›½', 1),\n",
       " ('ğŸ›¢', 1),\n",
       " ('ğŸ', 1),\n",
       " ('ğŸª', 1),\n",
       " ('ğŸ¥‘', 1),\n",
       " ('ğŸ—', 1),\n",
       " ('ğŸ™', 1),\n",
       " ('ğŸŒ†', 1),\n",
       " ('ğŸ›', 1),\n",
       " ('ğŸ¦…', 1),\n",
       " ('ğŸ”', 1),\n",
       " ('ğŸŒ¬', 1),\n",
       " ('ğŸšˆ', 1),\n",
       " ('ğŸ›¤', 1),\n",
       " ('ğŸ›', 1),\n",
       " ('ğŸ»', 1),\n",
       " ('â›µ', 1),\n",
       " ('ğŸ¦¹', 1),\n",
       " ('ğŸ‘»', 1),\n",
       " ('ğŸ¤ª', 1),\n",
       " ('ğŸ­', 1),\n",
       " ('ğŸ¯', 1),\n",
       " ('ğŸŒ', 1),\n",
       " ('ğŸ’¢', 1),\n",
       " ('ğŸ£', 1),\n",
       " ('ğŸ‘º', 1),\n",
       " ('ğŸ’¿', 1),\n",
       " ('ğŸ›', 1),\n",
       " ('ğŸ™‡', 1),\n",
       " ('ğŸ‘·', 1),\n",
       " ('ğŸ‚', 1),\n",
       " ('ğŸ›¹', 1),\n",
       " ('âŒ¨', 1),\n",
       " ('ğŸ“·', 1),\n",
       " ('ğŸ–¼', 1),\n",
       " ('ğŸ’«', 1),\n",
       " ('ğŸ’š', 1),\n",
       " ('ğŸ›¬', 1),\n",
       " ('ğŸ¤‘', 1),\n",
       " ('ğŸ¡', 1),\n",
       " ('ğŸŒ•', 1),\n",
       " ('ğŸ“…', 1),\n",
       " ('ğŸ§', 1),\n",
       " ('ğŸ“¡', 1),\n",
       " ('ğŸŒˆ', 1),\n",
       " ('ğŸ¤ ', 1),\n",
       " ('ğŸ˜Œ', 1),\n",
       " ('ğŸ”', 1),\n",
       " ('ğŸ”ˆ', 1),\n",
       " ('ğŸ™‹', 1),\n",
       " ('ğŸ›«', 1),\n",
       " ('ğŸ¤', 1),\n",
       " ('ğŸµ', 1),\n",
       " ('â¬›', 1),\n",
       " ('ğŸ–Œ', 1),\n",
       " ('ğŸ—“', 1),\n",
       " ('ğŸ', 1),\n",
       " ('ğŸ·', 1),\n",
       " ('â˜', 1),\n",
       " ('ğŸ™ˆ', 1),\n",
       " ('ğŸ’©', 1),\n",
       " ('ğŸ”‚', 1),\n",
       " ('ğŸ¸', 1),\n",
       " ('ğŸ‘¾', 1),\n",
       " ('ğŸ®', 1),\n",
       " ('â²', 1),\n",
       " ('ğŸ˜²', 1),\n",
       " ('âš½', 1),\n",
       " ('ğŸŒ©', 1),\n",
       " ('ğŸ˜¤', 1),\n",
       " ('ğŸ§­', 1),\n",
       " ('ğŸ¶', 1),\n",
       " ('â˜”', 1),\n",
       " ('â›ˆ', 1),\n",
       " ('ğŸŒ¹', 1),\n",
       " ('â¬†', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 2\n",
    "emojis = []\n",
    "for tweet in df['tweet_content']:\n",
    "    emojis.extend(e['emoji'] for e in emoji_lis(tweet))\n",
    "\n",
    "Counter(emojis).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>lemmatized_tweet</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naval</td>\n",
       "      <td>2019-08-07 22:36:56</td>\n",
       "      <td>naval</td>\n",
       "      <td>7566</td>\n",
       "      <td>1498</td>\n",
       "      <td>Unresolved thoughts, prematurely pushed out of...</td>\n",
       "      <td>[Unresolved, thought, ,, prematurely, pushed, ...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naval</td>\n",
       "      <td>2019-08-07 05:00:38</td>\n",
       "      <td>naval</td>\n",
       "      <td>21886</td>\n",
       "      <td>5984</td>\n",
       "      <td>The modern mind is overstimulated and the mode...</td>\n",
       "      <td>[The, modern, mind, is, overstimulated, and, t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naval</td>\n",
       "      <td>2019-08-07 04:52:33</td>\n",
       "      <td>naval</td>\n",
       "      <td>6462</td>\n",
       "      <td>1266</td>\n",
       "      <td>The Lindy Effect for startups:\\n\\nThe longer y...</td>\n",
       "      <td>[The, Lindy, Effect, for, startup, :, The, lon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naval</td>\n",
       "      <td>2019-08-06 08:35:26</td>\n",
       "      <td>naval</td>\n",
       "      <td>466</td>\n",
       "      <td>61</td>\n",
       "      <td>@orangebook_ This was a good tweet.</td>\n",
       "      <td>[@, orangebook_, This, wa, a, good, tweet, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naval</td>\n",
       "      <td>2019-08-06 07:33:20</td>\n",
       "      <td>naval</td>\n",
       "      <td>3971</td>\n",
       "      <td>906</td>\n",
       "      <td>Social media lowers the cost of raising &amp;amp; ...</td>\n",
       "      <td>[Social, medium, lower, the, cost, of, raising...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31110</th>\n",
       "      <td>Uncanny Insights</td>\n",
       "      <td>2018-12-20 05:28:36</td>\n",
       "      <td>uncannyinsights</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Our general behavior is the reflection of our ...</td>\n",
       "      <td>[Our, general, behavior, is, the, reflection, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31111</th>\n",
       "      <td>Uncanny Insights</td>\n",
       "      <td>2018-12-20 05:18:28</td>\n",
       "      <td>uncannyinsights</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>In every matter being an unorthodox is a sure ...</td>\n",
       "      <td>[In, every, matter, being, an, unorthodox, is,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31112</th>\n",
       "      <td>Uncanny Insights</td>\n",
       "      <td>2018-12-19 09:50:56</td>\n",
       "      <td>uncannyinsights</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>You can change your way of thinking, by changi...</td>\n",
       "      <td>[You, can, change, your, way, of, thinking, ,,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31113</th>\n",
       "      <td>Uncanny Insights</td>\n",
       "      <td>2018-12-19 05:49:03</td>\n",
       "      <td>uncannyinsights</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>People fear that they will be dispossessed if ...</td>\n",
       "      <td>[People, fear, that, they, will, be, disposses...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31114</th>\n",
       "      <td>Uncanny Insights</td>\n",
       "      <td>2018-12-18 05:59:09</td>\n",
       "      <td>uncannyinsights</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>To diagnose your thoughts solitude is the firs...</td>\n",
       "      <td>[To, diagnose, your, thought, solitude, is, th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30753 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            author_name           created_at           handle  likes  \\\n",
       "0                 Naval  2019-08-07 22:36:56            naval   7566   \n",
       "1                 Naval  2019-08-07 05:00:38            naval  21886   \n",
       "2                 Naval  2019-08-07 04:52:33            naval   6462   \n",
       "3                 Naval  2019-08-06 08:35:26            naval    466   \n",
       "4                 Naval  2019-08-06 07:33:20            naval   3971   \n",
       "...                 ...                  ...              ...    ...   \n",
       "31110  Uncanny Insights  2018-12-20 05:28:36  uncannyinsights      3   \n",
       "31111  Uncanny Insights  2018-12-20 05:18:28  uncannyinsights      2   \n",
       "31112  Uncanny Insights  2018-12-19 09:50:56  uncannyinsights     31   \n",
       "31113  Uncanny Insights  2018-12-19 05:49:03  uncannyinsights      5   \n",
       "31114  Uncanny Insights  2018-12-18 05:59:09  uncannyinsights     31   \n",
       "\n",
       "       retweets                                      tweet_content  \\\n",
       "0          1498  Unresolved thoughts, prematurely pushed out of...   \n",
       "1          5984  The modern mind is overstimulated and the mode...   \n",
       "2          1266  The Lindy Effect for startups:\\n\\nThe longer y...   \n",
       "3            61               @orangebook_ This was a good tweet.    \n",
       "4           906  Social media lowers the cost of raising &amp; ...   \n",
       "...         ...                                                ...   \n",
       "31110         1  Our general behavior is the reflection of our ...   \n",
       "31111         0  In every matter being an unorthodox is a sure ...   \n",
       "31112         4  You can change your way of thinking, by changi...   \n",
       "31113         0  People fear that they will be dispossessed if ...   \n",
       "31114         6  To diagnose your thoughts solitude is the firs...   \n",
       "\n",
       "                                        lemmatized_tweet  sentiment_score  \n",
       "0      [Unresolved, thought, ,, prematurely, pushed, ...               -2  \n",
       "1      [The, modern, mind, is, overstimulated, and, t...                2  \n",
       "2      [The, Lindy, Effect, for, startup, :, The, lon...                0  \n",
       "3          [@, orangebook_, This, wa, a, good, tweet, .]                1  \n",
       "4      [Social, medium, lower, the, cost, of, raising...               -1  \n",
       "...                                                  ...              ...  \n",
       "31110  [Our, general, behavior, is, the, reflection, ...               -1  \n",
       "31111  [In, every, matter, being, an, unorthodox, is,...                0  \n",
       "31112  [You, can, change, your, way, of, thinking, ,,...                1  \n",
       "31113  [People, fear, that, they, will, be, disposses...               -2  \n",
       "31114  [To, diagnose, your, thought, solitude, is, th...                1  \n",
       "\n",
       "[30753 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 3\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized_tweet'] = (\n",
    "    df['tweet_content']\n",
    "        .apply(lambda t: nltk.word_tokenize(t))\n",
    "        .apply(lambda words: [lemmatizer.lemmatize(w) for w in words])\n",
    ")\n",
    "\n",
    "with open('positive-words.txt', 'r') as pos_file, open('negative-words.txt', 'r') as neg_file:\n",
    "    pos_set = {line.rstrip() for line in pos_file}\n",
    "    neg_set = {line.rstrip() for line in neg_file}\n",
    "\n",
    "\n",
    "def counting_score(tweet):\n",
    "    sentiment_score = 0\n",
    "    for word in tweet:\n",
    "        if word in pos_set:\n",
    "            sentiment_score += 1\n",
    "        elif word in neg_set:\n",
    "            sentiment_score -= 1\n",
    "    return sentiment_score\n",
    "\n",
    "\n",
    "df['sentiment_score'] = df['lemmatized_tweet'].apply(lambda t: counting_score(t))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
